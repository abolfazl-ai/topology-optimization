{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21d8c7654a3d5f7e",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from modes import *\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, UpSampling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a837fe53-5683-480d-bb90-ee203c46dcbf",
   "metadata": {},
   "source": [
    "# Designing the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T11:43:49.040293600Z",
     "start_time": "2024-02-05T11:43:48.880680700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 201, 201, 64)      4096      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 201, 201, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 201, 201, 128)     147584    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 100, 100, 64)      73792     \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 100, 100, 1)       577       \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 200, 200, 1)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 299,905\n",
      "Trainable params: 299,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(201, 201, 7)))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), strides=2, activation='relu'))\n",
    "model.add(Conv2D(1, kernel_size=(3, 3), padding='same', activation='sigmoid'))\n",
    "model.add(UpSampling2D(size=(2, 2)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ee9e5b-b5fe-4fa4-a484-f6eabc6e1938",
   "metadata": {},
   "source": [
    "# Pre-processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e6ef8a-3596-4ffd-bffc-8b247ad4cda5",
   "metadata": {},
   "source": [
    "### Loading the data and formating it to the suitable shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa6741a0f406e7ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T14:40:52.979933600Z",
     "start_time": "2024-02-06T14:40:52.964060600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def load_data(bc_code, load_code, penal, r, vf, threshold=0.3):\n",
    "    bc_code, load_code, penal, r, vf = [param.numpy() for param in (bc_code, load_code, penal, r, vf)]\n",
    "    bc_code, load_code = bc_code.decode('utf-8'), load_code.decode('utf-8')\n",
    "    load_path = 'data/' + bc_code + '/' + load_code + '/'\n",
    "    code = f'{bc_code}-{load_code}-P{penal}-R{r:0.3f}-V{vf:0.3f}'\n",
    "\n",
    "    c = np.load(load_path + bc_code + load_code + '-C.npy')\n",
    "    ux = np.load(load_path + bc_code + load_code + '-X.npy')\n",
    "    uy = np.load(load_path + bc_code + load_code + '-Y.npy')\n",
    "\n",
    "    x = np.ones((201, 201, 7), dtype=np.float32)\n",
    "    x[:, :, 0] = MinMaxScaler().fit_transform(ux)\n",
    "    x[:, :, 1] = MinMaxScaler().fit_transform(uy)\n",
    "    x[:, :, 2] = MinMaxScaler().fit_transform(np.hypot(ux, uy))\n",
    "    x[:, :, 3] = MinMaxScaler().fit_transform(np.pad(c, pad_width=1, mode='edge')[0:-1, 0:-1])\n",
    "    x[:, :, 4], x[:, :, 5], x[:, :, 6] = penal, r, vf\n",
    "\n",
    "    y = np.load(load_path + 'output/' + code + '.npy')\n",
    "    y[y >= threshold] = 1\n",
    "    y[y < threshold] = 0\n",
    "\n",
    "    return x, y.astype(np.bool_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9e0e3ef7a5180b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T11:43:51.759040800Z",
     "start_time": "2024-02-05T11:43:51.734113700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def general_function(bc_code, load_code, penal, r, vf):\n",
    "    x, y = tf.py_function(load_data, (bc_code, load_code, penal, r, vf), (tf.float32, tf.bool))\n",
    "    x.set_shape(tf.TensorShape([201, 201, 7]))\n",
    "    y.set_shape(tf.TensorShape([200, 200]))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d113edf1-febc-4b7b-9c09-2a6562198dc6",
   "metadata": {},
   "source": [
    "### Filtering out the outliars and unusable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b608024c20731a09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T11:43:52.234834300Z",
     "start_time": "2024-02-05T11:43:52.219597700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def filter_data(bc_code, load_code, penal, r, vf):\n",
    "    bc_code, load_code, penal, r, vf = [param.numpy() for param in (bc_code, load_code, penal, r, vf)]\n",
    "    bc_code, load_code = bc_code.decode('utf-8'), load_code.decode('utf-8')\n",
    "    load_path = 'data/' + bc_code + '/' + load_code + '/'\n",
    "    code = f'{bc_code}-{load_code}-P{penal}-R{r:0.3f}-V{vf:0.3f}'\n",
    "    y_path = load_path + 'output/' + code + '.npy'\n",
    "    c_path = load_path + bc_code + load_code + '-C.npy'\n",
    "    return os.path.exists(y_path) and np.load(c_path).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36b6563-f531-490d-9a62-df3cf6a032cd",
   "metadata": {},
   "source": [
    "### Creating the train, validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a5f23d4dc5d50ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T14:31:49.743836800Z",
     "start_time": "2024-02-06T14:31:48.528855600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "parameters = [(b, l, p, r, v) for b in list(bcs.keys()) for l in list(loads.keys())\n",
    "              for p in ps for r in rs for v in vfs]\n",
    "\n",
    "train_val_params, test_params = train_test_split(parameters, test_size=0.1, shuffle=True)\n",
    "train_params, validation_params = train_test_split(train_val_params, test_size=0.1, shuffle=True)\n",
    "\n",
    "train_params = tuple(np.array(item) for item in zip(*train_params))\n",
    "validation_params = tuple(np.array(item) for item in zip(*validation_params))\n",
    "test_params = tuple(np.array(item) for item in zip(*test_params))\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(train_params)\n",
    "validation_ds = tf.data.Dataset.from_tensor_slices(validation_params)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ec89d6a25d3adb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T11:43:54.537618800Z",
     "start_time": "2024-02-05T11:43:54.265611500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_ds = train_ds.filter(lambda b, l, p, r, v: tf.py_function(filter_data, (b, l, p, r, v), tf.bool))\n",
    "train_ds = train_ds.map(lambda b, l, p, r, v: general_function(b, l, p, r, v))\n",
    "train_ds = train_ds.batch(20)\n",
    "\n",
    "validation_ds = validation_ds.filter(lambda b, l, p, r, v: tf.py_function(filter_data, (b, l, p, r, v), tf.bool))\n",
    "validation_ds = validation_ds.map(lambda b, l, p, r, v: general_function(b, l, p, r, v))\n",
    "validation_ds = validation_ds.batch(20)\n",
    "\n",
    "test_ds = test_ds.filter(lambda b, l, p, r, v: tf.py_function(filter_data, (b, l, p, r, v), tf.bool))\n",
    "test_ds = test_ds.map(lambda b, l, p, r, v: general_function(b, l, p, r, v))\n",
    "test_ds = test_ds.batch(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5e5574-5612-4edf-928c-68138126398e",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6358e504f134e1e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T08:44:01.092443200Z",
     "start_time": "2024-02-05T11:43:55.704121Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8912/8912 [==============================] - 75215s 8s/step - loss: 0.4547 - accuracy: 0.7790 - val_loss: 0.3988 - val_accuracy: 0.8132\n",
      "Epoch 2/10\n",
      "5069/8912 [================>.............] - ETA: 9:07:31 - loss: 0.3704 - accuracy: 0.8287"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(train_ds, epochs=10, batch_size=20, use_multiprocessing=True,\n",
    "                    validation_data=validation_ds, validation_batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e10cc35-1ecf-4ad1-aae9-19261406ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axis = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "axis[0].plot(history.history['accuracy'], label='Training Accuracy')\n",
    "axis[0].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "axis[0].set_xlabel('Epoch')\n",
    "axis[0].set_ylabel('Accuracy')\n",
    "axis[0].legend()\n",
    "\n",
    "# Plot loss\n",
    "axis[1].plot(history.history['loss'], label='Training Loss')\n",
    "axis[1].plot(history.history['val_loss'], label='Validation Loss')\n",
    "axis[1].set_xlabel('Epoch')\n",
    "axis[1].set_ylabel('Loss function')\n",
    "axis[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b920c1-09fe-4400-b71c-d8e86edb875c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T08:44:51.618295300Z",
     "start_time": "2024-02-06T08:44:51.216122500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1facdfc9bfea61a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T09:06:15.365320Z",
     "start_time": "2024-02-05T09:06:06.552935900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_ds, use_multiprocessing=True, batch_size=25)\n",
    "print(f'The model has the accuracy of {accuracy * 100:0.2f}% and the loss of {loss} on the testing data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd9e2021341603e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T14:49:26.230484400Z",
     "start_time": "2024-02-06T14:49:24.605911600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "batch_ds = next(test_ds.as_numpy_iterator())\n",
    "fig, ax = plt.subplots(3, 2, figsize=(10, 10))\n",
    "for i in range(3):\n",
    "    x = batch_ds[0][i]\n",
    "    y_true = batch_ds[1][i]\n",
    "    y_pred = model.predict(x.reshape((-1, 201, 201, 7)), verbose=0)[0, :, :, 0]\n",
    "    sns.heatmap(1 - y_true, ax=ax[i, 0], vmin=0, vmax=1, square=True, cmap='gray', cbar=False,\n",
    "                xticklabels=False, yticklabels=False).invert_yaxis()\n",
    "    ax[i, 0].set_title('True')\n",
    "    sns.heatmap(1 - y_pred, ax=ax[i, 1], vmin=0, vmax=1, square=True, cmap='gray', cbar=False,\n",
    "                xticklabels=False, yticklabels=False).invert_yaxis()\n",
    "    ax[i, 1].set_title('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501e1dbb12196956",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
